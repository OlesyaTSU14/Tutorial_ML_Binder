{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#pip install -r requirementsPyth.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATLAS Higgs Machine Learning Challenge 2014\n",
    "\n",
    "#The algorithms higgsml_opendata_tmva.py was changed and adapted to work on a laptop and lxplus using a package scikit-learn instead TMVA/BDT.\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "from array import array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, confusion_matrix\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "#with open('/Users/okuchins/Olesya_work/HigsML2014/S_learn/atlas-higgs-challenge-2014-v2.csv','rb') as f:\n",
    "#    reader = csv.reader(f)\n",
    "#    your_list = map(tuple, reader)\n",
    "\n",
    "#alldata = list(csv.reader(open('/Users/okuchins/Olesya_work/HigsML2014/S_learn/atlas-higgs-challenge-2014-v2.csv',\"rb\"), delimiter=','))\n",
    "#list = map(tuple, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header ['EventId', 'DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality', 'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta', 'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_all_pt', 'Weight', 'Label', 'KaggleSet', 'KaggleWeight']\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "datafile=\"atlas-higgs-challenge-2014-v2.csv\"\n",
    "# load the CSV file as a numpy matrix\n",
    "alldata = list(csv.reader(open(datafile,\"r\"), delimiter=','))\n",
    "\n",
    "# first line is the list of variables, put it aside\n",
    "header        = alldata.pop(0)\n",
    "\n",
    "print(\"header\", header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilabel 32\n"
     ]
    }
   ],
   "source": [
    "# deal with some exception\n",
    "iid=header.index(\"EventId\")\n",
    "ilabel=header.index(\"Label\")\n",
    "ikaggleset=header.index(\"KaggleSet\")\n",
    "ikaggleweight=header.index(\"KaggleWeight\")\n",
    "iweight=header.index(\"Weight\") # original weight     \n",
    "immc=header.index(\"DER_mass_MMC\")\n",
    "injet=header.index(\"PRI_jet_num\")\n",
    "exclude_index = [iid, ilabel, ikaggleset, ikaggleweight, iweight, immc, injet]\n",
    "print(\"ilabel\", ilabel) \n",
    "\n",
    "for entry in alldata:\n",
    "    for i in range(len(entry)):\n",
    "        if i in [iid,injet]:\n",
    "            entry[i]=int(entry[i])\n",
    "        elif i not in [ilabel,ikaggleset]:\n",
    "            entry[i]=float(entry[i])\n",
    "\n",
    "data_train = []\n",
    "data_test = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train is 250000\n",
      "data_train [[100000, 138.47, 51.655, 97.827, 27.98, 0.91, 124.711, 2.666, 3.064, 41.928, 197.76, 1.582, 1.396, 0.2, 32.638, 1.017, 0.381, 51.626, 2.273, -2.414, 16.824, -0.277, 258.733, 2, 67.435, 2.15, 0.444, 46.062, 1.24, -2.475, 113.497, 0.00081448039868, 1, 0, 0.00265331133733], [100001, 160.937, 68.768, 103.235, 48.146, -999.0, -999.0, -999.0, 3.473, 2.078, 125.157, 0.879, 1.414, -999.0, 42.014, 2.039, -3.011, 36.918, 0.501, 0.103, 44.704, -1.916, 164.546, 1, 46.226, 0.725, 1.158, -999.0, -999.0, -999.0, 46.226, 0.681041906806, 0, 0, 2.23358448717]]\n",
      "Number of test is 100000\n",
      "data_test [[350000, -999.0, 79.589, 23.916, 3.036, -999.0, -999.0, -999.0, 0.903, 3.036, 56.018, 1.536, -1.404, -999.0, 22.088, -0.54, -0.609, 33.93, -0.504, -1.511, 48.509, 2.022, 98.556, 0, -999.0, -999.0, -999.0, -999.0, -999.0, -999.0, -0.0, 1.38090387249, 0, 10, 11.2466766407], [350008, 70.958, 66.329, 60.95, 0.758, -999.0, -999.0, -999.0, 2.37, 0.758, 66.573, 1.593, -1.38, -999.0, 25.676, 1.513, 0.095, 40.897, 1.132, 2.434, 30.277, -1.389, 102.088, 0, -999.0, -999.0, -999.0, -999.0, -999.0, -999.0, -0.0, 1.41208474085, 0, 10, 11.5006270791]]\n"
     ]
    }
   ],
   "source": [
    "sumselsig=0.\n",
    "sumselbkg=0.\n",
    "sumallsig=0.\n",
    "sumallbkg=0.\n",
    "sumsubsig=0.\n",
    "sumsubbkg=0.\n",
    "t=0\n",
    "b=0\n",
    "v=0\n",
    "u=0\n",
    "\n",
    "sumselkagglesig=0.\n",
    "sumselkagglebkg=0.\n",
    "\n",
    "for entry in alldata:\n",
    "   \n",
    "    weight=entry[iweight]\n",
    "    kaggleweight=entry[ikaggleweight]    \n",
    "\n",
    "    if entry[ilabel]==\"s\":\n",
    "        entry[ilabel]=1\n",
    "        sumallsig+=weight\n",
    "    elif entry[ilabel]==\"b\":\n",
    "        sumallbkg+=weight\n",
    "        entry[ilabel]=0\n",
    "    else:  \n",
    "        entry[ilabel]=-999  \n",
    "\n",
    "    if entry[ikaggleset]==\"t\":\n",
    "        entry[ikaggleset]=0\n",
    "        t+=1 \n",
    "        data_train.append(entry)\n",
    "    elif entry[ikaggleset]==\"b\":\n",
    "        entry[ikaggleset]=10\n",
    "        b+=1\n",
    "        data_test.append(entry)\n",
    "    elif entry[ikaggleset]==\"v\":\n",
    "        entry[ikaggleset]=11\n",
    "        v+=1\n",
    "    elif entry[ikaggleset]==\"u\":\n",
    "        entry[ikaggleset]=100\n",
    "        u+=1      \n",
    "    else:\n",
    "        entry[ikaggleset]=-999\n",
    "\n",
    "    if entry[ikaggleset]!=10:\n",
    "        continue\n",
    "\n",
    "    if entry[ilabel]==1:\n",
    "        sumsubsig+=weight\n",
    "    else:\n",
    "        sumsubbkg+=weight  \n",
    "\n",
    "\n",
    "print(\"Number of train is\", (t))  \n",
    "print(\"data_train\", data_train[0:2])\n",
    "print(\"Number of test is\", (b))\n",
    "print(\"data_test\", data_test[0:2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X train is 250000\n",
      "x_train [[51.655, 97.827, 27.98, 0.91, 124.711, 2.666, 3.064, 41.928, 197.76, 1.582, 1.396, 0.2, 32.638, 1.017, 0.381, 51.626, 2.273, -2.414, 16.824, -0.277, 258.733, 67.435, 2.15, 0.444, 46.062, 1.24, -2.475, 113.497]]\n",
      "Length of Y train is 250000\n",
      "y_train [1]\n",
      "Length of X test is 100000\n",
      "x_test [[79.589, 23.916, 3.036, -999.0, -999.0, -999.0, 0.903, 3.036, 56.018, 1.536, -1.404, -999.0, 22.088, -0.54, -0.609, 33.93, -0.504, -1.511, 48.509, 2.022, 98.556, -999.0, -999.0, -999.0, -999.0, -999.0, -999.0, -0.0]]\n",
      "Length of Y test is 100000\n",
      "y_test [0]\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for row in data_train:\n",
    "    newrow = copy.deepcopy(row)\n",
    "    for el in sorted(exclude_index, reverse=True):\n",
    "        del newrow[el]\n",
    "    x_train.append(newrow)\n",
    "    y_train.append(row[ilabel])\n",
    "\n",
    "for row in data_test:\n",
    "    newrow = copy.deepcopy(row)\n",
    "    for el in sorted(exclude_index, reverse=True):\n",
    "        del newrow[el]\n",
    "    x_test.append(newrow)\n",
    "    y_test.append(row[ilabel]) \n",
    "    \n",
    "\n",
    "\n",
    "print(\"Length of X train is\", (len(x_train)))  \n",
    "print(\"x_train\", x_train[0:1])\n",
    "print(\"Length of Y train is\", (len(y_train)))  \n",
    "print(\"y_train\", y_train[0:1])\n",
    "print(\"Length of X test is\", (len(x_test)))\n",
    "print(\"x_test\", x_test[0:1]) \n",
    "print(\"Length of Y test is\", (len(y_test)))\n",
    "print(\"y_test\", y_test[0:1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_y_predicted [0 0 0 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#alldata.head()\n",
    "\n",
    "    \n",
    "    # sum event weight passing the selection. Of course in real life the threshold should be optimised\n",
    "\n",
    "#newlist=[] \n",
    "#signal = []\n",
    "#for row in your_list[1:]:\n",
    "    #if int(row[32]) == 0 && int(row[33]) == 0:\n",
    "     #   backgr.append(int(row[23]))\n",
    "    #else:\n",
    "    #    signal.append(int(row[23]))\n",
    "\n",
    "#print len(sinal)\n",
    "#signal_tr = signal[:len(signal)*0.7]\n",
    "#signal_ts = signal[len(signal)*0.7:]\n",
    "\n",
    "    #newlist.append({'EventId':row[0],'Weight':row[31],'Label':row[32],'KaggleSet':row[33],'KaggleWeight':row[34],'Pri_jet_num':row[23]})\n",
    "\n",
    "# where DecisionTrees, DecisionStumps and AdaBoost are\n",
    "# compared to each other\n",
    "#X, y = datasets.make_hastie_10_2(n_samples=12000, random_state=1)\n",
    "\n",
    "# Train on the first 2000, test on the rest\n",
    "\n",
    "\n",
    "\n",
    "#t_train, b_train = t[:2000], b[:2000]\n",
    "#t_test, b_test = t[2000:], b[2000:]\n",
    "\n",
    "\n",
    "# some shortcuts to select \"signal\" or \"background\"\n",
    "# entries in the feautre vector\n",
    "#signal = y_train > +0.1\n",
    "#background = y_train < -0.1\n",
    "\n",
    "#plt.scatter(X_train[signal,0], X_train[signal,1], c='red')\n",
    "#plt.scatter(X_train[background,0], X_train[background,1], c='blue')\n",
    "#plt.xlabel(\"Feature 0\")\n",
    "#plt.ylabel(\"Feature 1\")\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3,\n",
    "                            min_samples_leaf=0.01*len(x_train[0]))\n",
    "bdt = AdaBoostClassifier(dt,\n",
    "                         algorithm='SAMME',\n",
    "                         n_estimators=800,\n",
    "                         learning_rate=0.5)\n",
    "\n",
    "bdt.fit(x_train, y_train)\n",
    "sk_y_predicted = bdt.predict(x_test)\n",
    "print(\"sk_y_predicted\", sk_y_predicted[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79707\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85     65975\n",
      "           1       0.73      0.64      0.68     34025\n",
      "\n",
      "   micro avg       0.80      0.80      0.80    100000\n",
      "   macro avg       0.78      0.76      0.77    100000\n",
      "weighted avg       0.79      0.80      0.79    100000\n",
      "\n",
      "Confusion matrix:\n",
      "[[57803  8172]\n",
      " [12121 21904]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, sk_y_predicted))\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, sk_y_predicted,))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, sk_y_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
